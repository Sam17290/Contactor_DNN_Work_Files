from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation
import pandas as pd
import io
import os
import requests
import numpy as np
from sklearn import metrics

# from google.colab import drive
# drive.mount('/content/drive')

## Seeding to obtain replicable results
seed_value= 9
# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value
import os
os.environ['PYTHONHASHSEED']=str(seed_value)
# 2. Set the `python` built-in pseudo-random generator at a fixed value
import random
random.seed(seed_value)
# 3. Set the `numpy` pseudo-random generator at a fixed value
import numpy as np
np.random.seed(seed_value)
# 4. Set the `tensorflow` pseudo-random generator at a fixed value
import tensorflow as tf
tf.random.set_seed(seed_value)

path = "/content/drive/MyDrive/Latest_After_Defense_Neural_Networks_SLG_Faults/Contactor_Trip_Reconnection_Cases_Data_Final_Training_Final.csv"
df = pd.read_csv(path)

path1 = "/content/drive/MyDrive/Latest_After_Defense_Neural_Networks_SLG_Faults/Contactor_Trip_Reconnection_Cases_Data_Final_Testing_Final.csv"
df1 = pd.read_csv(path1)

path2 = "/content/drive/MyDrive/Latest_After_Defense_Neural_Networks_SLG_Faults/Contactor_Tripped_Cases_Data_Training_W_Norm_Final_Validation_Final.csv"
df2 = pd.read_csv(path2)

# Pandas to Numpy
x = df[['FA','FN', 'ST',]].values
y = df['T1'].values # regression

# Pandas to Numpy Testing
x1 = df1[['FA','FN', 'ST',]].values
y1 = df1['T1'].values # regression

# Pandas to Numpy Validation
x2 = df2[['FA','FN', 'ST',]].values
y2 = df2['T1'].values # regression

# Build the neural network
model = Sequential()
model.add(Dense(10, input_dim=x.shape[1], activation='relu')) # Hidden 1
# model.add(Dense(20, activation='relu')) # Hidden 2
model.add(Dense(4, activation='relu')) # Hidden 2
model.add(Dense(10, activation='relu')) # Hidden 3
model.add(Dense(5, activation='relu')) # Hidden 4
model.add(Dense(2, activation='relu')) # Hidden 5
model.add(Dense(1)) # Output
model.compile(loss='mean_squared_error', optimizer='adam')
# model.fit(x,y,verbose=0,epochs=2800)
model.fit(x, y, validation_data=(x2, y2),verbose=1,epochs=800)

pred = model.predict(x)
print(f"Shape1: {pred.shape}")
# print(pred[0:149])

pred1 = model.predict(x1)
print(f"Shape: {pred1.shape}")
# print(pred1[0:65])

# Measure RMSE error.  RMSE is common for regression.
score = np.sqrt(metrics.mean_squared_error(pred1,y1))
print(f"Final score Testing(RMSE): {score} ")

score1 = np.sqrt(metrics.mean_squared_error(pred,y))
print(f"Final score Training(RMSE): {score1} ")

# Final score Testing(RMSE): 2.3391489305110245 
# Final score Training(RMSE): 1.848739433151844 


# Final score Testing(RMSE): 2.560248389431697 
# Final score Training(RMSE): 2.40805074085472 With Validation

## Dump weights and biases 
#for layerNum, layer in enumerate(model.layers):
#    weights = layer.get_weights()[0]
#    biases = layer.get_weights()[1]
#    
#    for toNeuronNum, bias in enumerate(biases):
#        print(f'{bias}')
#    
#    for fromNeuronNum, wgt in enumerate(weights):
#        for toNeuronNum, wgt2 in enumerate(wgt):
#            print(f'{wgt2}')